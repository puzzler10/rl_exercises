{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the gridworld from example 3.8 in the book where we solve it through implementing dynamic programming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from functools import partial\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Parameters \n",
    "nrow = 5\n",
    "ncol = 5 \n",
    "k = 1  # number of moves between policy iterations\n",
    "gamma = 0.9  # discount factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup gameboard \n",
    "grid = np.zeros((nrow, ncol))\n",
    "# Add teleporters - start, end, score\n",
    "tele_start_l = [(0,1), (0,3)]\n",
    "tele_end_l   = [(4,1), (2,3)]\n",
    "tele_score_l = [10   , 5    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actions - up, down, left, right\n",
    "actions = [(-1,0), (1,0), (0,-1), (0,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_on_grid(pos): \n",
    "    if min(pos) < 0 or pos[0] >= nrow or pos[1] >= ncol:   \n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_action(pos, action): \n",
    "    \"\"\" move, score, and deal with teleporters\n",
    "    pos, action are tuples. \n",
    "    pos is where you are now\n",
    "    action is the coordinate change\"\"\"\n",
    "    reward = 0 \n",
    "    ### teleporter case\n",
    "    tele_flag = False\n",
    "    for i in range(len(tele_start_l)):\n",
    "        if pos == tele_start_l[i]:    \n",
    "            tele_flag = True\n",
    "            new_pos = tele_end_l[i]; \n",
    "            reward += tele_score_l[i]\n",
    "    if tele_flag == False: \n",
    "        ### no teleporter, make valid move \n",
    "        new_pos = tuple(np.add(pos,action))\n",
    "        if is_on_grid(new_pos) == False:   reward -=1 \n",
    "        if min(new_pos) < 0:      new_pos = (np.max([0, new_pos[0]]), \n",
    "                                             np.max([0, new_pos[1]]))\n",
    "        elif new_pos[0] >= nrow:  new_pos = ((nrow-1), new_pos[1])\n",
    "        elif new_pos[1] >= ncol:  new_pos = (new_pos[0], (ncol-1))\n",
    "    return (new_pos, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bellman_update(idx, reward_l, new_pos_l,pi):\n",
    "    return (pi[idx]*(reward_l[idx] + gamma * v[new_pos_l[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_value_for_square(pos,v,pi):\n",
    "    tmp = [eval_action(pos, action) for action in actions]\n",
    "    new_pos_l = [o[0] for o in tmp]\n",
    "    reward_l  = [o[1] for o in tmp]\n",
    "    # update the value function\n",
    "    v[pos] = sum(map(partial(bellman_update, reward_l=reward_l, \n",
    "                              new_pos_l = new_pos_l, pi=pi), range(len(pi))))\n",
    "    return(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_evaluation(policy,k=100): \n",
    "    v = np.zeros((nrow,ncol))\n",
    "    pos_l = [(x,y) for x in range(nrow) for y in range(ncol)]\n",
    "    for i in range(k): \n",
    "        for pos in pos_l: \n",
    "            pi = policy[pos[0]][pos[1]]\n",
    "            v = update_value_for_square(pos,v,pi)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_start = [0.25, 0.25, 0.25, 0.25]  # Start policy \n",
    "policy = [[pi_start for j in range(ncol)] for i in range(nrow)]  # one for each square\n",
    "v = policy_evaluation(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3,  8.8,  4.4,  5.3,  1.5],\n",
       "       [ 1.5,  3. ,  2.3,  1.9,  0.5],\n",
       "       [ 0.1,  0.7,  0.7,  0.4, -0.4],\n",
       "       [-1. , -0.4, -0.4, -0.6, -1.2],\n",
       "       [-1.9, -1.3, -1.2, -1.4, -2. ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we define a new policy based on the value function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_improvement(v):\n",
    "    # Define list to hold policy\n",
    "    policy = [[[0,0,0,0] for j in range(ncol)] for i in range(nrow)] \n",
    "    for pos in pos_l: \n",
    "        legal_moves = [is_on_grid(tuple(np.add(pos,action))) for action in actions]\n",
    "        values = [v[tuple(np.add(pos,act))] \n",
    "                  if legal else -99999999 for act, legal in zip(actions, legal_moves)]\n",
    "        max_val = max(values)\n",
    "        n_max_values = sum([1 if o == max_val else 0 for o in values])\n",
    "        pi_tmp = [1/n_max_values if o == max_val else 0 for o in values]\n",
    "        policy[pos[0]][pos[1]] = pi_tmp\n",
    "    return(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = policy_improvement(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Policy iteration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we cycle back and forth between the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_start = [0.25, 0.25, 0.25, 0.25]  \n",
    "policy = [[pi_start for j in range(ncol)] for i in range(nrow)] \n",
    "for i in range(10):\n",
    "    v = policy_evaluation(policy, k=10)\n",
    "    policy = policy_improvement(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.6,  17.1,  14.6,  13.4,  11.2],\n",
       "       [ 12.7,  14.6,  12.7,  11.2,  10. ],\n",
       "       [ 11.1,  12.7,  11.1,  10. ,   8.4],\n",
       "       [ 10. ,  11.1,  10. ,   8.4,   6.7],\n",
       "       [  7.1,  10. ,   7.1,   6.7,   5.2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 1.0],\n",
       "  [0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333],\n",
       "  [0, 0, 1.0, 0],\n",
       "  [0, 0, 1.0, 0],\n",
       "  [0, 0, 1.0, 0]],\n",
       " [[0.5, 0, 0, 0.5],\n",
       "  [1.0, 0, 0, 0],\n",
       "  [0.5, 0, 0.5, 0],\n",
       "  [1.0, 0, 0, 0],\n",
       "  [0.5, 0, 0.5, 0]],\n",
       " [[0.5, 0, 0, 0.5],\n",
       "  [1.0, 0, 0, 0],\n",
       "  [0.5, 0, 0.5, 0],\n",
       "  [1.0, 0, 0, 0],\n",
       "  [0.5, 0, 0.5, 0]],\n",
       " [[0.5, 0, 0, 0.5],\n",
       "  [1.0, 0, 0, 0],\n",
       "  [0.5, 0, 0.5, 0],\n",
       "  [0.5, 0, 0.5, 0],\n",
       "  [0.5, 0, 0.5, 0]],\n",
       " [[0.5, 0, 0, 0.5],\n",
       "  [1.0, 0, 0, 0],\n",
       "  [0.5, 0, 0.5, 0],\n",
       "  [1.0, 0, 0, 0],\n",
       "  [0.5, 0, 0.5, 0]]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
