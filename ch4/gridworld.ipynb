{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4x4 gridworld from example 4.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import packages and set initial variables   \n",
    "import numpy as np\n",
    "np.random.seed = 123\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "\n",
    "# This is our value function\n",
    "v = np.zeros((nrow,ncol))\n",
    "\n",
    "## Create the grid \n",
    "# The grid will be made up of empty strings except for the terminal states, \n",
    "# which will have 'T' \n",
    "grid = np.zeros((nrow,ncol), dtype='str')\n",
    "grid[0,0] = 'T'\n",
    "grid[nrow-1,ncol-1] = 'T'\n",
    "\n",
    "# Set up the coordinate changes of moving up, down, left, right \n",
    "# Note: this is the oppposite of the xy-plane. Rows is the x-axis, \n",
    "# columns is the y-axis\n",
    "actions = [(-1,0), (1,0), (0,-1), (0,1)]\n",
    "# The cutoffs represent an equiprobable random policy \n",
    "# We select a random number later and the cutoffs are the ranges for \n",
    "# each action. \n",
    "cutoffs = np.array([0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the value function by simulation \n",
    "n = 2000  # Number of episodes \n",
    "k = 10   # Maximum number of time steps per episode \n",
    "for x in range(nrow): \n",
    "    for y in range(ncol):\n",
    "        G = np.zeros(n)  # Our return for each episode\n",
    "        for i in range(n): \n",
    "            coord = [x,y]  # Starting position of the agent\n",
    "            r=0; cnt=0  # Reset from last simulation \n",
    "            while grid[tuple(coord)] != 'T' and cnt < k: \n",
    "                # get next coordinate\n",
    "                rnum = np.random.uniform()\n",
    "                coord = np.add(coord, actions[np.min(np.where(rnum < cutoffs))])\n",
    "                # adjust for going off the grid \n",
    "                coord[0] = max(0, coord[0]); coord[0] = min(coord[0], (nrow-1))\n",
    "                coord[1] = max(0, coord[1]); coord[1] = min(coord[1], (ncol-1))\n",
    "                # allocate reward, increase counter\n",
    "                r += -1; cnt += 1\n",
    "            G[i] = r\n",
    "        # The value is the average return for that starting state. \n",
    "        v[x,y] = np.mean(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -6.1, -8.4, -9. ],\n",
       "       [-6.2, -7.8, -8.4, -8.3],\n",
       "       [-8.3, -8.4, -7.8, -6.2],\n",
       "       [-9. , -8.4, -6.2,  0. ]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(v,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing v, can we find q? Use the equation\n",
    "$$ q_\\pi (s, a) = \\sum_{s'} p(s' | s,a) \\left[ r(s,a,s') + \\gamma v_\\pi(s') \\right] $$\n",
    "The term $ p(s'|s,a) = 1$ for our case, so shouldn't be too hard. We will assume that $ \\gamma $ is a parameter we can tweak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the action-value function q\n",
    "#\n",
    "# Set up 3D array for q\n",
    "# The first dimesnion holds the direction chosen. \n",
    "# Order is up, down, left, right\n",
    "q = np.zeros((4, nrow, ncol)) \n",
    "gamma = 0.9  # discount rate parameter \n",
    "for x in range(nrow): \n",
    "    for y in range(ncol): \n",
    "        for i, action in enumerate(actions): \n",
    "            # Get coordinate of the next state s'\n",
    "            s_prime = np.add((x,y), action)\n",
    "            # Adjust for going off the grid\n",
    "            s_prime[0] = max(0, s_prime[0]); s_prime[0] = min(s_prime[0], (nrow-1))\n",
    "            s_prime[1] = max(0, s_prime[1]); s_prime[1] = min(s_prime[1], (ncol-1))\n",
    "            # Allocate the action-value function \n",
    "            q[i,x,y] = -1 +  gamma * v[tuple(s_prime)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1. , -6.5, -8.6, -9.1],\n",
       "        [-1. , -6.5, -8.6, -9.1],\n",
       "        [-6.6, -8. , -8.6, -8.5],\n",
       "        [-8.4, -8.6, -8. , -6.6]],\n",
       "\n",
       "       [[-6.6, -8. , -8.6, -8.5],\n",
       "        [-8.4, -8.6, -8. , -6.6],\n",
       "        [-9.1, -8.5, -6.6, -1. ],\n",
       "        [-9.1, -8.5, -6.6, -1. ]],\n",
       "\n",
       "       [[-1. , -1. , -6.5, -8.6],\n",
       "        [-6.6, -6.6, -8. , -8.6],\n",
       "        [-8.4, -8.4, -8.6, -8. ],\n",
       "        [-9.1, -9.1, -8.5, -6.6]],\n",
       "\n",
       "       [[-6.5, -8.6, -9.1, -9.1],\n",
       "        [-8. , -8.6, -8.5, -8.5],\n",
       "        [-8.6, -8. , -6.6, -6.6],\n",
       "        [-8.5, -6.6, -1. , -1. ]]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(q,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
